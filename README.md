# Calculating Happiness Index

## Students

- Gariel Mahwastu
- Garien Rahadi
- Vedant Kanabar

## Data Collection and Cleanup

### World Development Indicators Data
1. The data for the World Development Indicators can be found in the World Development Indicators folder.
2. The `EUCountriesDevelopmentIndicators.csv `file is the CSV file downloaded from the World Bank website.
3. The `cleanData.py` is a python script to clean the data. This also contains the code and infromation on how the cleaning was done.
4. The `cleaned_EUCountriesDevelopmentIndicators.csv` file is the cleaned CSV file generated by the `cleanData.py`.

### Fraser Institute
1. The data from the Fraser Institute can be found in the Fraser Institute Raw Data folder
2. The `economicdata2012-2022.csv` file is the raw CSV file downloaded from Fraser Institute for economic factors
3. The `human-freedom-index-2023-datafile.xlsx` file is the raw XLSX file downloaded from Fraser Institute for human freedom factors
4. The `extract_economic_data.py` is a python script to clean the economicdata2012-2022.csv file. This also contains the code and infromation on how the cleaning was done.
5. The `extract_freedom_idx_data.py` is a python script to clean the human-freedom-index-2023-datafile.xlsx. This also contains the code and infromation on how the cleaning was done.
6. The `cleaned_economic_data.csv` is the cleaned CSV file generated by the `extract_economic_data.py`.
7. The `cleaned_freedom_idx_data.py` is the cleaned CSV file generated by the `extract_freedom_idx_data.py`.

### Happiness Index Report.
1. The data for the Happiness Index report can be found in the Happiness Index Raw data folder.
2. The `DataForTable2.1.xls` file is the XLS file downloaded from the Happiness Report website.
3. The `extract_data.py` is a python script to clean the data. This also contains the code and infromation on how the cleaning was done.
4. The `cleaned_happiness_index.csv` file is the cleaned CSV file generated by the `cleanData.py`.

### Combining data and creating features.
1. All processing data after combination and feature creation can be found in the Combining Data and Feature creation folder.
2. The `combine_data.py` is a python script to combine all the cleaned data from the 4 cleaned csv files described above. This also contains the code and infromation on how the cleaning was done.
3. The `combined_dataset.csv` file is the combined CSV file generated by the `combine_data.py` which combines all the cleaned data.
4. The `create_features.py` is a python script to create a JSON file creating features for the model with the same year. This will create a JSON file with an array of objects in the format below. The labels in this case correspond to the year and country the happiness index is for. The features are a list of key value pairs of feature name and value consistent across all features. The features contain information for only the given year.
5. The `feature.json` file is the JSON file generated by the `create_features.py` for features for the same year model.
6. The `create_features_year_back.py` is a python script to create a JSON file creating features for the model with two years. This will create a JSON file with an array of objects in the format below. The labels in this case correspond to the year and country the happiness index is for. The features are a list of key value pairs of feature name and value consistent across all features. The features contain information for the given year and the year prior.
7. The `feature_year_back.json` file is the JSON file generated by the `create_features_year_back.py` for features for the one year back model which handles indexes for the same year and the year prior.


JSON format for feature files:
```
[ {
    "labels": {
        "country": {name of country},
        "year": {datapoint year}
    },
    "happiness_index": {happiness index that year}
    "features": {
        "feature_1": {value of feature 1},
        "feature_2": {value of feature 2},
        ...,
    }
}, {...}, ... ]
```

## Data Visualization, Model Evaluation, and Model Training

### Model for same year
1. In the folder called "Model for same year". All files in this folder deal with features for the same year. You can find the python scripts that you can run for:
  - Generating data visualization (3d scatter plot) using dimensionality reduction functions such as PCA, MDS, and t-SNE
  - Model evaluation
  - Model hyperparameter optimization for random forest model and SVR model
  - Model training and determining top 10 features for random forest model and SVR model
2. The `model_PCA.py` is a python script to create a 3D model after PCA reduction to features for same year.
3. The `model_MDS.py` is a python script to create a 3D model after MDS reduction to features for same year.
4. The `model_tSNE.py` is a python script to create a 3D model after tSNE reduction to features for same year.
5. The `model_evaluation.py` is a python script to evaluate 5 different base models to see which one best fits out data. It also prints out the reults of the model evaluation and the best model for a given metric.
6. The `model_hyper_param_svr.py` is a python script to find the best hyper parameters for SVR model. It prints out the best model parameters at the end of a randomized search.
7. The `model_training_random_forest.py` is a python script to find the best hyper parameters for Random Forest model. It prints out the best model parameters at the end of a randomized search.
8. The `model_training_svr.py` is a python script to train an SVR model to fit the data. It uses the hyperparameters from the previous script and splits the data into 80% training, 20% testing for evaluation. It prints out the model evaluation values for the different metrics. It also created residual plots for the model and evaluates the most important features through feature permutation creating a bar graph for it as well.
9. The `model_training_random_forest.py` is a python script to train an Random Forest model to fit the data. It uses the hyperparameters from the previous script and splits the data into 80% training, 20% testing for evaluation. It prints out the model evaluation values for the different metrics. It also created residual plots for the model and evaluates the most important features through feature permutation creating a bar graph for it as well.
10. The `Support Vector Regression Important vectors graph.png` and `Support Vector Regression Residual plot.png` are the graphs created by `model_training_svr.py` for the SVR model.
11. The `Random Forest Regression Important vectors graph.png` and `Random Forest Regression Residual plot.png` are the graphs created by `model_training_random_forest.py` for the Random Forest model.
12. The `utils.py` file contains common functions used by all files.

### Model for one year back
1. In the folder called "Model for one year back". All files in this folder deal with features for the same year and one year back combined. You can find the python scripts that you can run for:
  - Generating data visualization (3d scatter plot) using dimensionality reduction functions such as PCA, MDS, and t-SNE
  - Model evaluation
  - Model hyperparameter optimization for random forest model and SVR model
  - Model training and determining top 10 features for random forest model and SVR model
2. The `model_PCA.py` is a python script to create a 3D model after PCA reduction to features for same year and one year back.
3. The `model_MDS.py` is a python script to create a 3D model after MDS reduction to features for same year and one year back.
4. The `model_tSNE.py` is a python script to create a 3D model after tSNE reduction to features for same year and one year back.
5. The `model_evaluation.py` is a python script to evaluate 5 different base models to see which one best fits out data. It also prints out the reults of the model evaluation and the best model for a given metric.
6. The `model_hyper_param_svr.py` is a python script to find the best hyper parameters for SVR model. It prints out the best model parameters at the end of a randomized search.
7. The `model_training_random_forest.py` is a python script to find the best hyper parameters for Random Forest model. It prints out the best model parameters at the end of a randomized search.
8. The `model_training_svr.py` is a python script to train an SVR model to fit the data. It uses the hyperparameters from the previous script and splits the data into 80% training, 20% testing for evaluation. It prints out the model evaluation values for the different metrics. It also created residual plots for the model and evaluates the most important features through feature permutation creating a bar graph for it as well.
9. The `model_training_random_forest.py` is a python script to train an Random Forest model to fit the data. It uses the hyperparameters from the previous script and splits the data into 80% training, 20% testing for evaluation. It prints out the model evaluation values for the different metrics. It also created residual plots for the model and evaluates the most important features through feature permutation creating a bar graph for it as well.
10. The `Support Vector Regression Important vectors graph.png` and `Support Vector Regression Residual plot.png` are the graphs created by `model_training_svr.py` for the SVR model.
11. The `Random Forest Regression Important vectors graph.png` and `Random Forest Regression Residual plot.png` are the graphs created by `model_training_random_forest.py` for the Random Forest model.
12. The `utils.py` file contains common functions used by all files.
